<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Guan Ming Lim</title>
  
  <meta name="author" content="Guan Ming Lim">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <!-- <link rel="icon" type="image/png" href="images/seal_icon.png"> -->
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Guan Ming Lim</name>
              </p>
              <!--<p>I work on markerless mocap of hand and object tracking.
              </p> -->
              
              <p style="text-align:center">
                <!-- <a href="mailto:guanming001@e.ntu.edu.sg">Email</a> &nbsp/&nbsp -->
                <!-- <a href="data/guanming-CV.pdf">CV</a> &nbsp/&nbsp -->
                <!-- <a href="data/guanming-bio.txt">Bio</a> &nbsp/&nbsp -->
                <a href="https://scholar.google.com/citations?user=RyreqWUAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/gmntu/">Github</a> &nbsp/&nbsp
                <a href="https://www.youtube.com/channel/UCRN_BMPLIJAhRW67F-aYSJw">YouTube</a>
              </p>
            </td>
<!--             <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/guanming.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/guanming_circle.jpg" class="hoverZoomLink"></a>
            </td> -->
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                I'm interested in combining research on computer vision, computer graphics and machine learning to understand human motion.
                Much of my research is on hand and object tracking from images.
                <!-- Representative papers are <span class="highlight">highlighted</span>. -->
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


<!--           <tr onmouseout="nerfbake_stop()" onmouseover="nerfbake_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='nerfbake_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/nerfbake_15.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/nerfbake_160.png' width="160">
              </div>
              <script type="text/javascript">
                function nerfbake_start() {
                  document.getElementById('nerfbake_image').style.opacity = "1";
                }

                function nerfbake_stop() {
                  document.getElementById('nerfbake_image').style.opacity = "0";
                }
                nerfbake_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="http://nerf.live">
              <papertitle>Baking Neural Radiance Fields for Real-Time View Synthesis</papertitle>
              </a>
              <br>
              <a href="https://phogzone.com/">Peter Hedman</a>,
              <a href="https://pratulsrinivasan.github.io/">Pratul Srinivasan</a>,
              <a href="https://bmild.github.io/">Ben Mildenhall</a>,
              <strong>Jonathan T. Barron</strong>,
              <a href="https://www.pauldebevec.com/">Paul Debevec</a>
              <br>
              <em>arXiv</em>, 2021 
              <br>
              <a href="http://nerf.live">project page</a>
              /
              <a href="https://arxiv.org/abs/2103.14645">arXiv</a>
              /
              <a href="https://www.youtube.com/watch?v=5jKry8n5YO8">video</a>
              /
              <a href="https://nerf.live/#demos">demo</a>
              <p></p>
              <p>Baking a trained NeRF into a sparse voxel grid of colors and features lets you render it in real-time in your browser.</p>
            </td> -->

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/rris40.jpg" alt="clean-usnob" width="160" height="160">
            </td>
            <td width="75%" valign="middle">
              <a href="https://ieeexplore.ieee.org/document/10591328/authors#authors/">
                <papertitle>Anatomical-Marker-Driven 3D Markerless Human Motion Capture</papertitle>
              </a>
              <br>
              <a href="https://www.ntu.edu.sg/rris/about-us/our-people/researchers/researcher-staff/dr-prayook-jetesiktat"> Prayook Jatesiktat</a>, <strong>Guan Ming Lim</strong>, Wee Sen Lim, <a href="https://dr.ntu.edu.sg/cris/rp/rp00218">Wei Tech Ang</a>
              <br>
              <em>JBHI</em>, 2024
              <br>
              <a href="https://koonyook.github.io/rris40/">project page</a>
              <p></p>              
              <p>The RRIS40 dataset uses anatomical landmarks from marker-based motion capture combined with deep learning techniques to achieve accurate 3D markerless human motion capture.</p>
            </td>
          </tr>


          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/obj.jpg" alt="clean-usnob" width="160" height="160">
            </td>
            <td width="75%" valign="middle">
              <a href="https://ieeexplore.ieee.org/document/10341147/">
                <papertitle>Real-time Tracking of Handheld Object from Color or Depth Images</papertitle>
              </a>
              <br>
              <strong>Guan Ming Lim</strong>, <a href="https://www.ntu.edu.sg/rris/about-us/our-people/researchers/researcher-staff/dr-prayook-jetesiktat"> Prayook Jatesiktat</a>, <a href="https://dr.ntu.edu.sg/cris/rp/rp00218">Wei Tech Ang</a>
              <br>
              <em>EMBC</em>, 2023
              <br>
              <a href="https://gmntu.github.io/obj/">project page</a>
              <p></p>              
              <p>Real-time, accurate, and robust tracking of a rigid object using image-based methods such as efficient projective point correspondence and precomputed spare viewpoint information.</p>
            </td>
          </tr>


          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/psa.jpg" alt="clean-usnob" width="160" height="160">
            </td>
            <td width="75%" valign="middle">
              <a href="https://ieeexplore.ieee.org/document/10340284/">
                <papertitle>Wireless Pressure Sensor Array Module for Sensorized Object</papertitle>
              </a>
              <br>
              <strong>Guan Ming Lim</strong>, <a href="https://www.ntu.edu.sg/rris/about-us/our-people/researchers/researcher-staff/dr-prayook-jetesiktat"> Prayook Jatesiktat</a>, <a href="https://www.ntu.edu.sg/rris/about-us/our-people/researchers/researcher-staff/christopher-kuah-wee-keong">Christopher Wee Keong Kuah</a>, <a href="https://dr.ntu.edu.sg/cris/rp/rp00218">Wei Tech Ang</a>
              <br>
              <em>EMBC</em>, 2023
              <br>
              <a href="https://gmntu.github.io/psa/">project page</a>
              <p></p>              
              <p>A low-cost, modular, and wireless pressure sensor array that can generate real-time pressure distribution map for object pose estimation and grasp classification.</p>
            </td>
          </tr>


          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/mobile_hand.jpg" alt="clean-usnob" width="160" height="160">
            </td>
            <td width="75%" valign="middle">
              <a href="https://link.springer.com/chapter/10.1007%2F978-3-030-63820-7_52">
                <papertitle>MobileHand: Real-Time 3D Hand Shape and Pose Estimation from Color Image</papertitle>
              </a>
              <br>
              <strong>Guan Ming Lim</strong>, <a href="https://www.ntu.edu.sg/rris/about-us/our-people/researchers/researcher-staff/dr-prayook-jetesiktat"> Prayook Jatesiktat</a>, <a href="https://dr.ntu.edu.sg/cris/rp/rp00218">Wei Tech Ang</a>
              <br>
              <em>ICONIP</em>, 2020
              <br>
              <a href="https://gmntu.github.io/mobilehand/">project page</a>
              /
              <a href="https://github.com/gmntu/mobilehand">code</a>
              /
              <a href="https://www.youtube.com/watch?v=bvVnJkGhJlI">video</a>
              <p></p>              
              <p>Real-time estimation of 3D hand shape and pose from a single RGB image running at over 110 Hz on a GPU or 75 Hz on a CPU.</p>
            </td>
          </tr>


          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/mirror_hand.jpg" alt="clean-usnob" width="160" height="160">
            </td>
            <td width="75%" valign="middle">
              <a href="https://ieeexplore.ieee.org/abstract/document/9176728/">
                <papertitle>Camera-based Hand Tracking using a Mirror-based Multi-view Setup</papertitle>
              </a>
              <br>
              <strong>Guan Ming Lim</strong>, <a href="https://www.ntu.edu.sg/rris/about-us/our-people/researchers/researcher-staff/dr-prayook-jetesiktat"> Prayook Jatesiktat</a>, <a href="https://www.ntu.edu.sg/rris/about-us/our-people/researchers/researcher-staff/christopher-kuah-wee-keong">Christopher Wee Keong Kuah</a>, <a href="https://dr.ntu.edu.sg/cris/rp/rp00218">Wei Tech Ang</a>
              <br>
              <em>EMBC</em>, 2020
              <br>
              <a href="https://gmntu.github.io/mirror/">project page</a>
              /
              <a href="https://github.com/gmntu/mirror">code</a>
              /
              <a href="https://www.youtube.com/watch?v=X8sVhl8Wswk">video</a>
              <p></p>              
              <p>A camera-based system for markerless hand pose estimation using a mirror-based multi-view setup to eliminate the complexity of synchronizing multiple cameras and reduce the issue of occlusion.</p>
            </td>
          </tr>


          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/hand_obj_seg.jpg" alt="clean-usnob" width="160" height="160">
            </td>
            <td width="75%" valign="middle">
              <a href="https://ieeexplore.ieee.org/abstract/document/8857700/">
                <papertitle>Hand and Object Segmentation from Depth Image using Fully Convolutional Network</papertitle>
              </a>
              <br>
              <strong>Guan Ming Lim</strong>, <a href="https://www.ntu.edu.sg/rris/about-us/our-people/researchers/researcher-staff/dr-prayook-jetesiktat"> Prayook Jatesiktat</a>, <a href="https://www.ntu.edu.sg/rris/about-us/our-people/researchers/researcher-staff/christopher-kuah-wee-keong">Christopher Wee Keong Kuah</a>, <a href="https://dr.ntu.edu.sg/cris/rp/rp00218">Wei Tech Ang</a>
              <br>
              <em>EMBC</em>, 2019
              <br>
              <a href="https://gmntu.github.io/hoseg/">project page</a>
              /
              <a href="https://github.com/gmntu/hoseg">code</a>
              /
              <a href="https://www.youtube.com/watch?v=SNuUrp2QiqY">video</a>
              <p></p>              
              <p>Semantic segmentation of body parts (e.g. hand and arm) and objects from depth image. A Fully Convolutional Neural Network is trained on synthetic data with some level of generalization on real data.</p>
            </td>
          </tr>


          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/sdf_net.jpg" alt="clean-usnob" width="160" height="160">
            </td>
            <td width="75%" valign="middle">
              <a href="https://link.springer.com/chapter/10.1007/978-3-319-93698-7_3/">
                <papertitle>SDF-Net: Real-Time Rigid Object Tracking Using a Deep Signed Distance Network</papertitle>
              </a>
              <br>
              <a href="https://www.ntu.edu.sg/rris/about-us/our-people/researchers/researcher-staff/dr-prayook-jetesiktat"> Prayook Jatesiktat</a>, <a href="https://www.ntu.edu.sg/rris/about-us/our-people/researcher-staff/dr-foo-ming-jeat">Ming Jeat Foo</a>, <strong>Guan Ming Lim</strong>, <a href="https://dr.ntu.edu.sg/cris/rp/rp00218">Wei Tech Ang</a>
              <br>
              <em>ICCS</em>, 2018
              <br>
              <a href="https://drive.google.com/drive/folders/1NF0wPz9xdR7uIWDdkpS9mvhxvwqcXPKC">supplementary material</a>
              <p></p>              
              <p>SDF-Net is a simple multilayer perceptron (with a memory footprint of < 10 kB) that is used to model the signed distance function (SDF) of a rigid object for real-time tracking (≈ 1.29 ms per frame on 1 CPU core) of the object using a single depth camera.</p>
            </td>
          </tr>


        </tbody></table>


        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Other Projects</heading>
            </td>
          </tr>


          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/hand_rom.jpg" alt="clean-usnob" width="160" height="160">
            </td>
            <td width="75%" valign="middle">
              <a href="https://gmntu.github.io/handrom/">
                <papertitle>Development of an Accessible Camera-based System for Measuring Hand Joint Range of Motion</papertitle>
              </a>
              <br>
              <strong>Guan Ming Lim</strong>, <a href="https://www.ntu.edu.sg/rris/about-us/our-people/researchers/researcher-staff/dr-prayook-jetesiktat"> Prayook Jatesiktat</a>, <a href="https://www.ntu.edu.sg/rris/about-us/our-people/researchers/researcher-staff/christopher-kuah-wee-keong">Christopher Wee Keong Kuah</a>, <a href="https://dr.ntu.edu.sg/cris/rp/rp00218">Wei Tech Ang</a>
              <br>
              <em>CAREhab, Singapore Rehabilitation Conference</em>, 2020
              <br>
            </td>
          </tr>


        </tbody></table>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:center;font-size:small;">
                Design and source code from <a style="font-size:small;" href="https://jonbarron.info">Jon Barron's website</a>
              </p>
            </td>
          </tr>
        </table>


      </td>
    </tr>
  </table>
</body>

</html>
